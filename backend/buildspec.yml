version: 0.2

phases:
  install:
    runtime-versions:
      nodejs: 20
      python: 3.11
    commands:
      - echo "Installing AWS CDK CLI..."
      - npm install -g aws-cdk@latest
      - cd backend
      - npm install

  pre_build:
    commands:
      - echo "Building TypeScript..."
      - npm run build
      - echo "Bootstrapping CDK..."
      - cdk bootstrap --require-approval never

  build:
    commands:
      - |
        if [ "$ACTION" = "destroy" ]; then
          echo "Destroying stack..."
          cdk destroy LOCstack --force \
            --context projectName="$PROJECT_NAME" \
            --context dataBucketName="$DATA_BUCKET_NAME" \
            --context bedrockModelId="$BEDROCK_MODEL_ID"
        else
          echo "========================================="
          echo "Deploying CDK Infrastructure First"
          echo "========================================="
          
          echo "Deploying CDK stack (creates ECR repository)..."
          cdk deploy LOCstack --require-approval never \
            --context projectName="$PROJECT_NAME" \
            --context dataBucketName="$DATA_BUCKET_NAME" \
            --context bedrockModelId="$BEDROCK_MODEL_ID" \
            --outputs-file outputs.json
          
          echo "Extracting outputs..."
          DATA_BUCKET=$(cat outputs.json | jq -r '.LOCstack.DataBucketName // empty')
          TRANSFORMATION_BUCKET=$(cat outputs.json | jq -r '.LOCstack.TransformationBucketName // empty')
          SUPPLEMENTAL_BUCKET=$(cat outputs.json | jq -r '.LOCstack.SupplementalBucketName // empty')
          API_URL=$(cat outputs.json | jq -r '.LOCstack.APIGatewayURL // empty')
          AMPLIFY_APP_ID=$(cat outputs.json | jq -r '.LOCstack.AmplifyAppId // empty')
          BUILDS_BUCKET=$(cat outputs.json | jq -r '.LOCstack.BuildsBucketName // empty')
          ECR_REPOSITORY_URI=$(cat outputs.json | jq -r '.LOCstack.ECRRepositoryUri // empty')
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          
          # Validate critical variables
          echo "Validating CDK outputs..."
          if [ -z "$DATA_BUCKET" ] || [ "$DATA_BUCKET" = "empty" ]; then
            echo "‚úó ERROR: DATA_BUCKET not found in CDK outputs"
            exit 1
          fi
          if [ -z "$TRANSFORMATION_BUCKET" ] || [ "$TRANSFORMATION_BUCKET" = "empty" ]; then
            echo "‚úó ERROR: TRANSFORMATION_BUCKET not found in CDK outputs"
            exit 1
          fi
          if [ -z "$SUPPLEMENTAL_BUCKET" ] || [ "$SUPPLEMENTAL_BUCKET" = "empty" ]; then
            echo "‚úó ERROR: SUPPLEMENTAL_BUCKET not found in CDK outputs"
            echo "‚úó This is required for Bedrock Data Automation"
            exit 1
          fi
          echo "‚úì All required CDK outputs validated"
          echo "  - Data Bucket: $DATA_BUCKET"
          echo "  - Transformation Bucket: $TRANSFORMATION_BUCKET"
          echo "  - Supplemental Bucket: $SUPPLEMENTAL_BUCKET"
          
          echo "========================================="
          echo "Building Fargate Docker Image"
          echo "========================================="
          echo "Using CDK-created ECR repository: $ECR_REPOSITORY_URI"
          
          # Build Fargate Docker image using the CDK-created ECR repository
          cd fargate
          chmod +x build.sh
          
          # Override the repository name to use the CDK-created one
          export ECR_REPOSITORY=$(echo "$ECR_REPOSITORY_URI" | cut -d'/' -f2)
          echo "Using ECR repository: $ECR_REPOSITORY"
          
          ./build.sh
          cd ..
          
          echo ""
          echo "========================================="
          echo "Next.js Frontend Build and Deployment"
          echo "========================================="
          
          # Check if Frontend directory exists
          if [ -d "../frontend" ]; then
            cd ../frontend
            
            echo "‚úÖ Frontend directory found"
            echo "üì¶ Installing dependencies..."
            npm install
            
            # Set up environment variables for Next.js
            echo "‚öôÔ∏è  Creating production environment..."
            echo "NEXT_PUBLIC_API_BASE_URL=$API_URL" > .env.production
            echo "NEXT_PUBLIC_CHAT_ENDPOINT=${API_URL}chat" >> .env.production
            echo "NEXT_PUBLIC_HEALTH_ENDPOINT=${API_URL}health" >> .env.production
            echo "NEXT_PUBLIC_AWS_REGION=$CDK_DEFAULT_REGION" >> .env.production
            
            # Build Next.js app with static export
            echo "üî® Building Next.js application for static export..."
            npm run build
            
            # Export static files (required for Amplify ZIP deployment)
            echo "üì§ Exporting static files..."
            npx next export
            
            # Verify export succeeded
            if [ ! -d "out" ]; then
              echo "‚ùå ERROR: Next.js export failed - out directory not found!"
              echo "‚ö†Ô∏è  Make sure your next.config.js has: output: 'export'"
              exit 1
            fi
            
            echo "‚úÖ Next.js static export successful"
            
            # Create deployment package with exported static files
            echo "üì¶ Creating deployment package..."
            cd out
            zip -r ../../frontend-static.zip . -x "*.DS_Store"
            cd ../../backend
            
            # Upload to builds bucket and deploy to Amplify
            if [ -n "$BUILDS_BUCKET" ] && [ "$BUILDS_BUCKET" != "empty" ] && [ -n "$AMPLIFY_APP_ID" ] && [ "$AMPLIFY_APP_ID" != "empty" ]; then
              BUILD_KEY="builds/frontend-static-$(date +%s).zip"
              
              echo "üì§ Uploading static build to S3: $BUILD_KEY"
              aws s3 cp ../frontend-static.zip "s3://$BUILDS_BUCKET/$BUILD_KEY"
              echo "‚úÖ Build artifact uploaded to S3"
              
              # Deploy to Amplify using S3 source
              echo "üöÄ Starting Amplify deployment..."
              aws amplify start-deployment \
                --app-id "$AMPLIFY_APP_ID" \
                --branch-name "main" \
                --source-url "s3://$BUILDS_BUCKET/$BUILD_KEY" \
                --region "$CDK_DEFAULT_REGION"
              
              echo "‚úÖ Amplify deployment started"
              echo "üì± Amplify App URL: https://main.$AMPLIFY_APP_ID.amplifyapp.com"
              echo "‚è≥ Deployment will complete in 2-5 minutes"
              
              FRONTEND_DEPLOYED="true"
            else
              echo "‚ùå ERROR: Missing BUILDS_BUCKET or AMPLIFY_APP_ID"
              echo "BUILDS_BUCKET: $BUILDS_BUCKET"
              echo "AMPLIFY_APP_ID: $AMPLIFY_APP_ID"
              FRONTEND_DEPLOYED="false"
            fi
          else
            echo "‚ö†Ô∏è Frontend directory not found at ../frontend"
            FRONTEND_DEPLOYED="false"
          fi
          
          echo ""
          echo "========================================="
          echo "Knowledge Base Configuration"
          echo "========================================="
          echo "‚úÖ Knowledge Base created by CDK with GraphRAG (Neptune Analytics)"
          echo "‚úÖ S3 Data Source configured automatically"
          echo "‚úÖ All IAM roles and permissions configured"
          echo ""
          
          # Extract Knowledge Base ID from CDK outputs
          KB_ID=$(cat outputs.json | jq -r '.LOCstack.KnowledgeBaseId // empty')
          
          if [ -z "$KB_ID" ] || [ "$KB_ID" = "empty" ]; then
            echo "‚úó ERROR: Knowledge Base ID not found in CDK outputs"
            echo "‚úó CDK should have created the Knowledge Base automatically"
            exit 1
          fi
          
          echo "‚úì Knowledge Base ID: $KB_ID"
          echo "‚úì GraphRAG with Neptune Analytics enabled"
          echo "‚úì Embedding Model: amazon.titan-embed-text-v2:0"
          echo "‚úì Context Enrichment: anthropic.claude-3-haiku"
          echo ""
          
          # Update Lambda environment variables with KB ID
          echo "Updating Lambda environment variables..."
          
          # Update fargate-trigger Lambda
          FARGATE_ENV=$(aws lambda get-function-configuration \
            --function-name "${PROJECT_NAME}-fargate-trigger" \
            --region "$CDK_DEFAULT_REGION" \
            --query 'Environment.Variables' \
            --output json)
          
          echo "$FARGATE_ENV" | jq \
            --arg kb_id "$KB_ID" \
            --arg bucket "$DATA_BUCKET" \
            '{Variables: (. + {KNOWLEDGE_BASE_ID: $kb_id, BUCKET_NAME: $bucket})}' > /tmp/fargate_env.json
          
          aws lambda update-function-configuration \
            --function-name "${PROJECT_NAME}-fargate-trigger" \
            --environment file:///tmp/fargate_env.json \
            --region "$CDK_DEFAULT_REGION" >/dev/null
          
          # Update kb-sync-trigger Lambda
          KB_SYNC_ENV=$(aws lambda get-function-configuration \
            --function-name "${PROJECT_NAME}-kb-sync-trigger" \
            --region "$CDK_DEFAULT_REGION" \
            --query 'Environment.Variables' \
            --output json)
          
          echo "$KB_SYNC_ENV" | jq \
            --arg kb_id "$KB_ID" \
            '{Variables: (. + {KNOWLEDGE_BASE_ID: $kb_id})}' > /tmp/kb_sync_env.json
          
          aws lambda update-function-configuration \
            --function-name "${PROJECT_NAME}-kb-sync-trigger" \
            --environment file:///tmp/kb_sync_env.json \
            --region "$CDK_DEFAULT_REGION" >/dev/null
          
          # Update chat-handler Lambda
          CHAT_ENV=$(aws lambda get-function-configuration \
            --function-name "${PROJECT_NAME}-chat-handler" \
            --region "$CDK_DEFAULT_REGION" \
            --query 'Environment.Variables' \
            --output json)
          
          echo "$CHAT_ENV" | jq \
            --arg kb_id "$KB_ID" \
            --arg model_id "$BEDROCK_MODEL_ID" \
            '{Variables: (. + {KNOWLEDGE_BASE_ID: $kb_id, MODEL_ID: $model_id})}' > /tmp/chat_env.json
          
          aws lambda update-function-configuration \
            --function-name "${PROJECT_NAME}-chat-handler" \
            --environment file:///tmp/chat_env.json \
            --region "$CDK_DEFAULT_REGION" >/dev/null
          
          echo "‚úì Lambda environment variables updated"
          echo ""
          
          # Step 8: Automatically start data collection
          echo ""
          echo "========================================="
          echo "Step 8: Starting Automatic Data Collection"
          echo "========================================="
          echo "This will collect bills from Congresses 1-16 (all types)"
          echo "Fargate task will:"
          echo "  1. Call Congress API for all bills"
          echo "  2. Extract text using Textract"
          echo "  3. Upload to S3"
          echo "  4. Auto-trigger Knowledge Base sync"
          echo ""
          
          # Trigger Fargate data collection using environment variables
          echo "Triggering Fargate task (using hardcoded environment variables)..."
          echo "Parameters:"
          echo "  - Congresses: 1-16"
          echo "  - Bill types: hr,s,hjres,sjres,hconres,sconres,hres,sres"
          echo "  - Function: ${PROJECT_NAME}-fargate-trigger"
          echo ""
          
          aws lambda invoke \
            --function-name "${PROJECT_NAME}-fargate-trigger" \
            --region "$CDK_DEFAULT_REGION" \
            /tmp/fargate_response.json
          
          # Simple success check - if Lambda returns 200, we're good
          if [ -f "/tmp/fargate_response.json" ]; then
            LAMBDA_STATUS=$(cat /tmp/fargate_response.json | jq -r '.StatusCode // 0')
            if [ "$LAMBDA_STATUS" = "200" ]; then
              echo "‚úì Fargate data collection started successfully!"
              echo ""
              echo "üìä What's happening now:"
              echo "  - Fargate task is starting (takes 2-3 minutes)"
              echo "  - Will collect bills from Congresses 1-16"
              echo "  - All bill types: HR, S, HJRES, SJRES, HCONRES, SCONRES, HRES, SRES"
              echo "  - Data will be uploaded to S3"
              echo "  - Knowledge Base sync will start automatically when complete"
              echo ""
              echo "üîç Monitor progress:"
              echo "  aws logs tail /ecs/${PROJECT_NAME}-collector --follow --region ${CDK_DEFAULT_REGION}"
              echo ""
              echo "üìà Expected timeline:"
              echo "  - Next 5-15 minutes: Data collection"
              echo "  - Following 5-10 minutes: Knowledge Base sync"
              echo "  - Total time: ~20-30 minutes until chat API is ready"
              FARGATE_SUCCESS="200"
            else
              echo "‚ö† Lambda returned status: $LAMBDA_STATUS"
              echo "Check Lambda logs for details:"
              echo "  aws logs tail /aws/lambda/${PROJECT_NAME}-fargate-trigger --follow --region ${CDK_DEFAULT_REGION}"
              FARGATE_SUCCESS="failed"
            fi
          else
            echo "‚ö† No response file created"
            FARGATE_SUCCESS="failed"
          fi
          
          echo ""
          echo "========================================="
          echo "‚úì Deployment Complete!"
          echo "========================================="
          echo "Infrastructure Status:"
          echo "  Graph ID: $GRAPH_ID"
          echo "  Knowledge Base ID: $KB_ID"
          echo "  Data Source ID: $DS_ID"
          echo "  Data Bucket: $DATA_BUCKET"
          echo ""
          if [ "$FARGATE_SUCCESS" = "200" ]; then
            echo "üöÄ Automated Data Collection: STARTED"
            echo "   The system is now collecting historical bills automatically."
            echo "   No further action required - everything is automated!"
          else
            echo "‚ö†Ô∏è  Automated Data Collection: FAILED"
            echo "   You can start data collection manually:"
            echo "   python test_complete_pipeline.py"
          fi
          echo "========================================="
          
          # Extract optional outputs (may not exist in all stacks)
          STATE_MACHINE_ARN=$(cat outputs.json | jq -r '.LOCstack.StateMachineArn // empty')
          API_URL=$(cat outputs.json | jq -r '.LOCstack.APIGatewayURL // empty')
          CHAT_ENDPOINT=$(cat outputs.json | jq -r '.LOCstack.ChatEndpoint // empty')
          
          if [ -z "$DATA_BUCKET" ]; then
            echo "‚ùå ERROR: Could not extract Data Bucket from CDK deployment"
            exit 1
          fi
          
          if [ -z "$TRANSFORMATION_BUCKET" ]; then
            echo "‚ùå ERROR: Could not extract Transformation Bucket from CDK deployment"
            exit 1
          fi
          
          if [ -z "$SUPPLEMENTAL_BUCKET" ]; then
            echo "‚ùå ERROR: Could not extract Supplemental Bucket from CDK deployment"
            exit 1
          fi
          
          echo "‚úÖ Deployment successful!"
          echo ""
          echo "========================================="
          echo "Deployment Summary"
          echo "========================================="
          echo "Data Bucket: $DATA_BUCKET"
          echo "Transformation Bucket: $TRANSFORMATION_BUCKET"
          echo "Supplemental Bucket: $SUPPLEMENTAL_BUCKET"
          echo "Knowledge Base ID: $KB_ID (CDK-managed with GraphRAG)"
          echo "Neptune Analytics: Automatically provisioned by CDK"
          
          if [ -n "$STATE_MACHINE_ARN" ]; then
            echo "State Machine ARN: $STATE_MACHINE_ARN"
          fi
          
          if [ -n "$API_URL" ]; then
            echo "API Gateway URL: $API_URL"
          fi
          
          if [ -n "$CHAT_ENDPOINT" ]; then
            echo "Chat Endpoint: $CHAT_ENDPOINT"
          fi
          
          # Frontend URLs
          if [ -n "$BUILDS_BUCKET" ]; then
            echo "Builds Bucket: $BUILDS_BUCKET"
          fi
          
          if [ -n "$AMPLIFY_APP_ID" ] && [ "$AMPLIFY_APP_ID" != "null" ]; then
            AMPLIFY_URL="https://main.${AMPLIFY_APP_ID}.amplifyapp.com"
            echo "Frontend Amplify URL: $AMPLIFY_URL"
            if [ "$FRONTEND_DEPLOYED" = "true" ]; then
              echo "Frontend Status: ‚úÖ DEPLOYED"
            else
              echo "Frontend Status: ‚ö†Ô∏è  NOT DEPLOYED"
            fi
          fi
          echo ""
          echo ""
          echo "========================================="
          echo "Next Steps & Monitoring"
          echo "========================================="
          
          if [ "$FARGATE_SUCCESS" = "200" ]; then
            echo "‚úÖ System Status: FULLY AUTOMATED"
            echo ""
            echo "üåê Next.js Frontend Deployed:"
            if [ -n "$AMPLIFY_APP_ID" ] && [ "$AMPLIFY_APP_ID" != "null" ]; then
              echo "  Amplify URL: https://main.${AMPLIFY_APP_ID}.amplifyapp.com"
            fi
            echo ""
            echo "üìà What's Happening Now:"
            echo "  1. Fargate task is collecting bills from Congress API"
            echo "  2. Text extraction with Textract (for PDFs)"
            echo "  3. Files being uploaded to S3"
            echo "  4. Knowledge Base sync will start automatically"
            echo "  5. Chat API will be ready in ~20-30 minutes"
            echo "  6. Frontend is already live and ready to use!"
            echo ""
            echo "üîç Monitor Real-time Progress:"
            echo "  aws logs tail /ecs/${PROJECT_NAME}-collector --follow --region ${CDK_DEFAULT_REGION}"
            echo ""
            echo "üìä Check Data Collection:"
            echo "  aws s3 ls s3://${DATA_BUCKET}/bills/ --recursive"
            echo ""
            echo "üß† Check Knowledge Base Status:"
            echo "  aws bedrock-agent list-ingestion-jobs \\"
            echo "    --knowledge-base-id $KB_ID \\"
            echo "    --data-source-id $DS_ID \\"
            echo "    --region ${CDK_DEFAULT_REGION}"
          else
            echo "‚ö†Ô∏è  Manual Setup Required:"
            echo ""
            echo "üåê Next.js Frontend Deployed:"
            if [ -n "$AMPLIFY_APP_ID" ] && [ "$AMPLIFY_APP_ID" != "null" ]; then
              echo "  Amplify URL: https://main.${AMPLIFY_APP_ID}.amplifyapp.com"
            fi
            echo ""
            echo "1. Start data collection:"
            echo "   python test_complete_pipeline.py"
            echo ""
            echo "2. Or trigger Fargate manually:"
            echo "   aws lambda invoke \\"
            echo "     --function-name ${PROJECT_NAME}-fargate-trigger \\"
            echo "     --payload '{\"body\":\"{\\\"start_congress\\\":1,\\\"end_congress\\\":16}\"}' \\"
            echo "     --region ${CDK_DEFAULT_REGION} response.json"
          fi
          echo ""
        fi

  post_build:
    commands:
      - echo "========================================="
      - echo "Build Complete"
      - echo "========================================="
      - |
        if [ "$ACTION" = "deploy" ]; then
          if [ "$FARGATE_SUCCESS" = "200" ]; then
            echo "üéâ SUCCESS: Fully Automated Pipeline Deployed!"
            echo "üåê Next.js Frontend is live and ready to use!"
            echo "üìä Data collection is running automatically"
            echo "ü§ñ Chat API will be ready in 20-30 minutes"
            echo "üîç Monitor progress with the commands shown above"
          else
            echo "‚úÖ Infrastructure deployed successfully"
            echo "üåê Next.js Frontend is live and ready to use!"
            echo "‚ö†Ô∏è  Data collection needs manual trigger"
            echo "üìã Use: python test_complete_pipeline.py"
          fi
        else
          echo "‚úÖ Stack destroyed successfully"
        fi

artifacts:
  files:
    - "**/*"
  base-directory: "backend/cdk.out"